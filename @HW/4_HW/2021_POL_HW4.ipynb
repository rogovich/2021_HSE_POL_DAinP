{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ4. Классификация новостей\n",
    "Будем собирать новости и классифицировать их по рубрикам с помощью МО.\n",
    "\n",
    "## Сбор данных (5 баллов)\n",
    "\n",
    "Нужно собрать данные из пяти рубрик сайта lenta.ru. Этот пункт можно пропустить и перейти ко второй части, за которую можно получить 7 баллов.\n",
    "\n",
    "1. Ссылки на рубрики даны ниже. \n",
    "   \n",
    "       1.1 На каждой из этих страниц новости рубрики располагаются в блоке, размеченном тегом `<<div class=\"item news b-tabloid__topic_news\">`.\n",
    "       1.2 Далее внутри этого блока нужно найти все ссылки (тег `<a>`) и забрать из них значение атрибута (`href`).\n",
    "       1.3 Каждую ссылку нужно восстановить до полного вида, добавив вначало строку `'https://lenta.ru'`\n",
    "    \n",
    "2. После того как для рубрики собраны все ссылки, нужно с каждой из них собрать текст новости.\n",
    "    \n",
    "        2.1 Новость располагается в блоке, размеченном тегом `<div class='b-topic__content'>`.\n",
    "        2.2 Текст новости разбит на параграфы (тег `<p>`), особенностью которых является то, что у них нет класса (`class=None`)\n",
    "        2.3 Текст новости нужно собрать в единую строку. Например, собрав все параграфы в список, а потом объединить их через `.join()` и пустую строку.\n",
    "\n",
    "3. Каждую новость нужно сохранить вместе с лейблом — названием рубрики, к которой она принадлежит. Лейбл проще всего достать из ссылки рубрики, разбив ее с помощью `.split()` по слэшу.\n",
    "\n",
    "В итоге у вас должен получиться датафрейм pandas со всеми собранными новстями (~350 штук), в котором есть две колонки — `'text'` и '`label'`. Удобнее всего его получить написав фукнцию, которая работает следующим образом:\n",
    "\n",
    "    1. Функция принимает в качестве аргумента ссылку на рубрику.\n",
    "    2. Из ссылки извлекается название рубрики.\n",
    "    3. Создается объект BeautifulSoup с исходным текстом страницы рубрики.\n",
    "    4. В объекте BS находится нужный блок с новостями рубрики (см. п. 1.1).\n",
    "    5. Внутри этого блока находятся все ссылки на статьи рубрики (п. 1.2 и 1.3).\n",
    "    6. Создается список, в котором будут храниться новости рубрики.\n",
    "    7. Затем для каждой ссылки рубрики выполняются следующие операции:\n",
    "        1) Создается объект BS из исходного кода страницы новости.\n",
    "        2) Внутри объекта BS ищется блок с текстом новости (п. 2.1).\n",
    "        3) Внутри этого блока ищутся все параграфы текста, которые объединяются в единую строку (п. 2.2 и 2.3)\n",
    "        4) В список из пункта 6 этой инструкции добавляется кортеж или список из двух строк — текст новости и ее рубрика.\n",
    "        5) После того как функция прошлась по всем новостям рубрики, она возвращает список из пункта 6 со всеми новостями рубрики.\n",
    "    8. Функция запускается для всех рубрик. Результаты работы функции (списки кортежей) добавляются в новый список через `+=` или метод `.extend()`.\n",
    "\n",
    "4. Получившийся список преобразуется в объект pandas.DataFrame с колонками `'text'` и `'label'`. Итоговый датафрейм сохраняется в файл с расширением '.csv'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubrics = ['https://lenta.ru/rubrics/science/', 'https://lenta.ru/rubrics/culture/',\n",
    "           'https://lenta.ru/rubrics/sport/', 'https://lenta.ru/rubrics/economics/',\n",
    "           'https://lenta.ru/rubrics/travel/']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация текста (3 балла)\n",
    "\n",
    "Если вы не собрали самостоятельно данные, то можно воспользоваться датасетом по ссылке.\n",
    "\n",
    "1. Вам нужно написать функцию, которая будет нормализовать текст — очистит его от знаков препинания и приведет все слова к словарной форме.\n",
    "    \n",
    "        1.1 Внутри функции используйте шаблон регулярных выражений, чтобы оставить в тексте только слова, написанные кириллицей. Слова с написанием через дефис должны оставаться одним токеном (например, 'из-за'). Например, можно получить список всех токенов из новости с помощью `re.find_all()`.\n",
    "        1.2 Каждое слово нужно привести к словарной форме. Например, это можно сделать методом normal_forms класса MorphAnalyzer из библиотеки pymorphy2. Первая форма в этом списке — наиболее вероятная.\n",
    "        \n",
    "Ваша функция должна принимать на вход строку, а возвращать ее нормализованный вариант.\n",
    "\n",
    "2. Примените вашу функцию к колонке 'text' и сохраните отнормализованный текст в новой колонке датафрейма.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ученые Университета Торонто в Канаде определил...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Международная группа ученых раскрыла загадку, ...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>«Роскосмос» намерен выделить на первый этап из...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Специалисты Потсдамского института изменения к...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Microsoft отказалась от выпуска операционной с...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  Ученые Университета Торонто в Канаде определил...  science\n",
       "1  Международная группа ученых раскрыла загадку, ...  science\n",
       "2  «Роскосмос» намерен выделить на первый этап из...  science\n",
       "3  Специалисты Потсдамского института изменения к...  science\n",
       "4  Microsoft отказалась от выпуска операционной с...  science"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(all_news, columns=['text', 'label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rogovich/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import re\n",
    "lemm = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = re.findall(r'\\b[А-яЕё]+(?:-[А-яЕё]+)*\\b', text)\n",
    "    return ' '.join([lemm.normal_forms(word)[0] for word in text])\n",
    "    \n",
    "df['text'] = df['text'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(df['text'], df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CountVectorizer(max_df=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = model.fit_transform(X_tr)\n",
    "test_features = model.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['science', 'sport', 'science', 'economics', 'culture', 'economics',\n",
       "       'economics', 'science', 'sport', 'science', 'science', 'science',\n",
       "       'economics', 'economics', 'economics', 'travel', 'science',\n",
       "       'sport', 'sport', 'science', 'science', 'economics', 'travel',\n",
       "       'culture', 'travel', 'culture', 'science', 'culture', 'science',\n",
       "       'science', 'economics', 'science', 'economics', 'travel',\n",
       "       'science', 'culture', 'travel', 'culture', 'travel', 'culture',\n",
       "       'travel', 'economics', 'culture', 'travel', 'culture', 'sport',\n",
       "       'science', 'culture', 'economics', 'culture', 'science', 'culture',\n",
       "       'economics', 'economics', 'science', 'sport', 'economics',\n",
       "       'culture', 'science', 'sport', 'sport', 'science', 'science',\n",
       "       'economics', 'sport', 'economics', 'culture', 'travel',\n",
       "       'economics', 'travel', 'economics', 'economics', 'sport',\n",
       "       'culture', 'science', 'science', 'economics', 'travel', 'travel',\n",
       "       'culture', 'culture', 'culture', 'science', 'travel', 'science',\n",
       "       'culture', 'travel', 'travel', 'travel', 'science'], dtype=object)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier()\n",
    "forest.fit(train_features, y_tr)\n",
    "forest.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9222222222222223"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy_score(forest.predict(test_features), y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culture</th>\n",
       "      <th>economics</th>\n",
       "      <th>science</th>\n",
       "      <th>sport</th>\n",
       "      <th>travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>culture</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economics</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>travel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           culture  economics  science  sport  travel\n",
       "culture         18          0        0      0       0\n",
       "economics        0         18        3      0       0\n",
       "science          0          2       21      0       0\n",
       "sport            1          0        0     10       0\n",
       "travel           0          0        1      0      16"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_te, forest.predict(test_features), \n",
    "            labels=sorted(set(y_te))), columns = sorted(set(y_te)), \n",
    "            index=sorted(set(y_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_te).count('sport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(forest.predict(test_features)).count('culture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 science economics\n",
      "16 economics science\n",
      "29 economics science\n",
      "35 sport culture\n",
      "48 science economics\n",
      "82 travel science\n",
      "89 economics science\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_te)):\n",
    "    if list(y_te)[i] != list(forest.predict(test_features))[i]:\n",
    "        print(i, list(y_te)[i], list(forest.predict(test_features))[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_te' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7914d51189e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m89\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_te' is not defined"
     ]
    }
   ],
   "source": [
    "X_te.iloc[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-00cf07b74dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
